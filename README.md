create env, install requirements then run this command
```wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q8_0.bin```
This will install the model.
Then to run the chainlit ```chainlit run model.py -w```
